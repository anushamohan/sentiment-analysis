{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiating spark session\n",
    "import pyspark as ps\n",
    "\n",
    "conf = ps.SparkConf() \\\n",
    "    .setAppName(\"My App\") \\\n",
    "    .setMaster(\"local[*]\")\n",
    "sc = ps.SparkContext(conf=conf)\n",
    "\n",
    "spark = ps.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading amazon reviews json file\n",
    "reviews = spark.read.json(\"data/reviews_Musical_Instruments_5.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(asin=u'1384719342', helpful=[0, 0], overall=5.0, reviewText=u\"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\", reviewTime=u'02 28, 2014', reviewerID=u'A2IBPI20UZIR0U', reviewerName=u'cassandra tu \"Yeah, well, that\\'s just like, u...', summary=u'good', unixReviewTime=1393545600),\n",
       " Row(asin=u'1384719342', helpful=[13, 14], overall=5.0, reviewText=u\"The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better than I had expected.As an added bonus, one of the screens carries a small hint of the smell of an old grape candy I used to buy, so for reminiscent's sake, I cannot stop putting the pop filter next to my nose and smelling it after recording. :DIf you needed a pop filter, this will work just as well as the expensive ones, and it may even come with a pleasing aroma like mine did!Buy this product! :]\", reviewTime=u'03 16, 2013', reviewerID=u'A14VAT5EAX3D9S', reviewerName=u'Jake', summary=u'Jake', unixReviewTime=1363392000),\n",
       " Row(asin=u'1384719342', helpful=[1, 1], overall=5.0, reviewText=u'The primary job of this device is to block the breath that would otherwise produce a popping sound, while allowing your voice to pass through with no noticeable reduction of volume or high frequencies. The double cloth filter blocks the pops and lets the voice through with no coloration. The metal clamp mount attaches to the mike stand secure enough to keep it attached. The goose neck needs a little coaxing to stay where you put it.', reviewTime=u'08 28, 2013', reviewerID=u'A195EZSQDW3E21', reviewerName=u'Rick Bennette \"Rick Bennette\"', summary=u'It Does The Job Well', unixReviewTime=1377648000)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the structure of that dataframe, and the column detected in the json content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we will be using the columns reviewText and overall rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_pro = reviews.select(\"reviewText\", \"overall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- overall: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_pro.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using group by, the number of reviews per rating was calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "reviews_count = reviews_pro.groupBy(reviews_pro.overall).agg(F.count(reviews_pro.reviewText).alias('RatingCount'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|overall|RatingCount|\n",
      "+-------+-----------+\n",
      "|    1.0|        217|\n",
      "|    4.0|       2084|\n",
      "|    3.0|        772|\n",
      "|    2.0|        250|\n",
      "|    5.0|       6938|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I will be using only extreme ratings {1.0, 5.0}. Based on the table above, the number of samples needed to build a balanced set were calculated below to have the same number of reviews in 1.0 and 5.0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg = reviews_pro.filter(reviews_pro[\"overall\"] <= 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = reviews_pro.filter(reviews_pro[\"overall\"] >= 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.random import RandomRDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_data = neg.sample(False, 0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in negative rating:  194\n"
     ]
    }
   ],
   "source": [
    "print \"number of samples in negative rating: \", neg_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_data = pos.sample(False, 0.031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in positive rating:  208\n"
     ]
    }
   ],
   "source": [
    "print \"number of samples in positive rating: \", pos_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a single dataframe containing the samples from both the balanced neg and pos classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = neg_data.union(pos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a function func_rating to derive the target variable, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func_rating(rating):\n",
    "    if rating == 1.0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "func_udf = udf(func_rating, IntegerType())\n",
    "result_df = data.withColumn(\"label\", func_udf(data.overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(reviewText=u\"It hums, crackles, and I think I'm having problems with my equipment.  As soon as I use any of my other cords then the problem is gone.  Hosa makes some other products that have good value.  But based on my experience I don't recommend this one.\", overall=1.0, label=0),\n",
       " Row(reviewText=u\"I'm a pro-cheapo and I hated this thing. They're noisy, and the cables feel really cheap, gummy-like. Drop few more bucks and get something else!\", overall=1.0, label=0),\n",
       " Row(reviewText=u'Received it in time, standard blister packaging but the cable stopped working after 45 days. Since I was out of 30 days return time, sent an email to the manufacturer but no response till today.', overall=1.0, label=0),\n",
       " Row(reviewText=u\"These things are terrible. One wouldn't fit in my soundboard, another wouldn't lock in my mic. Plain and simple....if your looking for crap that doesn't work....buy this.\", overall=1.0, label=0),\n",
       " Row(reviewText=u\"This is a cheap piece of junk that does what it says, it distorts, You want something to make your guitar sound like junk, this will do it. Why pedals that make your guitar sound like a piece of junk are the most popular is beyond me. This is not a boutique Distortion pedal like Hendrix would use. Boutique and distortion are an oxymoron.These things are built with heavy metal, it should last, I kinda hope it doesn't(just kidding), you want distortion, you got distortion\", overall=1.0, label=0),\n",
       " Row(reviewText=u\"Here's the deal with this pedal. It is inexpensive and you can get a better pedal with barely a bit more money and sometimes a little less money. In my opinion, for spending less than $100 for a distortion pedal, whether it is your first pedal or 700th pedal, a few more bucks will get you the MXR Badass distortion which has a much crisper tone to it.\", overall=1.0, label=0),\n",
       " Row(reviewText=u\"These came stock on my Jackson Kelly KEXMG. All the other guitars I own have Schaller buttons on them and I have one main strap I use for all of the guitars. I figured since the guitar came with them I would try them out. Not twenty min later I was removing them and putting Schaller buttons in their place. Here the 3 major reasons I did not like them over Schaller:1- Bulky. They stick out too far and on any guitar with a strap button on the back it jabs you in the stomach or below!2- Problems engaging. I would push them into the receiver and they pop back out. It wasn't until I forced them in while pushing the button that they went in a stayed in. Schallers click in and you know they are ready to go.3- Cheap. They just feel cheap. Thin metal is used in comparison to the Schallers; which have a very heavy and solid feel to them.For a few bucks more I'll stick with Schaller's. I have been using them for 10+ years and have never seen one fail.\", overall=1.0, label=0),\n",
       " Row(reviewText=u'I purchased this after reading the great reviews but like a few of the comments that are on here lately this thing is not good. Looked almost used when it arrived and the gooseneck stand is useless. Does not come even close to being able to hold up the weight of the filter. I would have returned it but I completely destroyed the package getting it open (which oddly had staples holding it closed).', overall=1.0, label=0),\n",
       " Row(reviewText=u'wind screen is way too big its bulky and to me useless, the screen came out, was thinking of glueing it back in but went to ebay and bought 2 metal mesh pop filters cheaper that is MUCH better...avoid this!!', overall=1.0, label=0),\n",
       " Row(reviewText=u\"I got this for my Boss Loop Station, but it doesn't work very well.  I keep hoping I'll find something it DOES work well with...\", overall=1.0, label=0)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the schema of final dataframe\n",
    "result_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexing_pipeline function is used below that takes a dataframe and a column to specify which field to apply the TFIDF on as inputs. It returns two things: first, the same DataFrame with a field 'features' and second, the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nlp_pipeline import indexing_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, voc = indexing_pipeline(result_df, inputCol=\"reviewText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(reviewText=u\"It hums, crackles, and I think I'm having problems with my equipment.  As soon as I use any of my other cords then the problem is gone.  Hosa makes some other products that have good value.  But based on my experience I don't recommend this one.\", overall=1.0, label=0, bow=[u'crackl', u'problem', u'equip', u'other', u'cord', u'problem', u'hosa', u'other', u'product', u'good', u'valu', u'experi'], vector_tf=SparseVector(1124, {2: 1.0, 6: 2.0, 9: 1.0, 14: 2.0, 64: 1.0, 242: 1.0, 277: 1.0, 351: 1.0, 887: 1.0}), features=SparseVector(1124, {2: 1.414, 6: 3.4725, 9: 1.8881, 14: 4.4295, 64: 3.2909, 242: 3.6964, 277: 3.6964, 351: 3.9195, 887: 4.9003}))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying naive bayes algorithm for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing NaiveBayes and specifying the columns for features (featureCol), labels (labelCol) and prediction (predictionCol). Then applying .fit() method on training set to obtain and use a model on the testing test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "model = nb.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying the model on the test set\n",
    "prediction = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n",
      "|          reviewText|prediction|         probability|\n",
      "+--------------------+----------+--------------------+\n",
      "|...for something,...|       1.0|[4.82112594208346...|\n",
      "|A great little pa...|       0.0|[0.99994898159018...|\n",
      "|At the time I bou...|       0.0|[1.0,3.4785709140...|\n",
      "|Be careful; I hav...|       1.0|[0.25986707347735...|\n",
      "|Bought it after r...|       0.0|[0.99999999995016...|\n",
      "|Bought this a whi...|       1.0|[0.01638607509435...|\n",
      "|Can't believe the...|       0.0|[0.96362221099522...|\n",
      "|Could not get to ...|       1.0|[0.00349439710197...|\n",
      "|DOWNGRADE TO 1-O ...|       0.0|[1.0,2.2325069633...|\n",
      "|Disappointing; wa...|       1.0|[0.25947854189704...|\n",
      "|Doesn't reduce so...|       1.0|[2.03052760753931...|\n",
      "|Go build your own...|       0.0|[0.99999999928353...|\n",
      "|I got one of thes...|       0.0|[1.0,6.6954417461...|\n",
      "|I had some issues...|       0.0|[0.99825573233647...|\n",
      "|I have always lov...|       0.0|[0.99999999999995...|\n",
      "|I have had this t...|       0.0|[0.88577968449275...|\n",
      "|I have several MX...|       1.0|[2.85336794576116...|\n",
      "|I ordered 1 just ...|       1.0|[0.00121453809180...|\n",
      "|I ordered this pl...|       0.0|[1.0,4.6315003217...|\n",
      "|I own the SN-8, w...|       0.0|[0.99942384292781...|\n",
      "+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select('reviewText', 'prediction', 'probability').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the MulticlassClassificationEvaluator to obtain an evaluation of the accuracy of the classification.\n",
    "\n",
    "Applying the instance on the prediction and label columns, by using .evaluate(). It will compute accuracy (or any other given metric) based on the differences observed between these two columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mce = MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6967824440471745"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of the NaiveBayes results\n",
    "\n",
    "The NaiveBayes model provides an internal matrix model.theta that can be converted into a numpy array with model.theta.toArray(). This matrix contains two columns corresponding to the two classes: 0 for neg and 1 for pos.\n",
    "\n",
    "The values inside that matrix correspond, for each class, to the prior probabilities used to compute the likelihood of a document to belong to the class. In this implementation, the model.theta matrix doesn't provide probabilities, but log of probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.93572547, -4.67371078],\n",
       "       [-5.23820439, -4.49589982],\n",
       "       [-5.57048511, -5.02677174],\n",
       "       ..., \n",
       "       [-9.43459814, -6.95831888],\n",
       "       [-7.65959083, -7.56291775],\n",
       "       [-9.43459814, -9.33792506]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.theta.toArray().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining words that are related to the pos class, and words that are related to the neg class. Ranking these words based on decreasing prior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "thetaarray = model.theta.toArray().T\n",
    "\n",
    "vocab_size = len(voc)\n",
    "\n",
    "dtype = [('label', 'S10'), ('neg', float), ('pos', float)]\n",
    "prob_values = [ (voc[i],\n",
    "                 np.exp(thetaarray[i,0])*(1-np.exp(thetaarray[i,1])),\n",
    "                 (1-np.exp(thetaarray[i,0]))*np.exp(thetaarray[i,1]))\n",
    "               for i in range(vocab_size) ]\n",
    "\n",
    "a = np.array(prob_values, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'guitar', 0.0071181537240466494, 0.0092704629488804986)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('string',   5.25055388e-03,  0.01109541),\n",
       "       ('guitar',   7.11815372e-03,  0.00927046),\n",
       "       ('great',   2.14154191e-03,  0.00783009),\n",
       "       ('pedal',   5.97409159e-03,  0.00744584),\n",
       "       ('capo',   1.61514003e-03,  0.00717606),\n",
       "       ('sound',   4.45302925e-03,  0.00687892),\n",
       "       ('good',   3.78364791e-03,  0.00653497),\n",
       "       ('microphon',   1.01312105e-03,  0.00629162),\n",
       "       ('best',   1.12448134e-03,  0.0061038 ),\n",
       "       ('voic',   7.94716234e-05,  0.00549679),\n",
       "       ('strap',   6.52520934e-03,  0.00528761),\n",
       "       ('easi',   4.68080934e-04,  0.00503271),\n",
       "       ('year',   2.46737561e-03,  0.00495576),\n",
       "       ('other',   4.91219607e-03,  0.00480189),\n",
       "       ('tuner',   1.84837020e-03,  0.00472864),\n",
       "       ('pick',   3.22103449e-03,  0.00454266),\n",
       "       ('condens',   7.95487633e-05,  0.00453154),\n",
       "       ('set',   2.51230195e-03,  0.0044814 ),\n",
       "       ('much',   1.58538169e-03,  0.00412629),\n",
       "       ('i',   3.04198753e-03,  0.00410816)], \n",
       "      dtype=[('label', 'S10'), ('neg', '<f8'), ('pos', '<f8')])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(a, order='pos')[::-1][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('guitar',  0.00711815,  0.00927046),\n",
       "       ('amp',  0.00680733,  0.00409939),\n",
       "       ('strap',  0.00652521,  0.00528761),\n",
       "       ('pedal',  0.00597409,  0.00744584),\n",
       "       ('product',  0.00564209,  0.00355777),\n",
       "       ('string',  0.00525055,  0.01109541),\n",
       "       ('problem',  0.00520585,  0.00125114),\n",
       "       ('other',  0.0049122 ,  0.00480189),\n",
       "       ('way',  0.00482289,  0.00108855),\n",
       "       ('time',  0.00458384,  0.00344471),\n",
       "       ('thing',  0.00457128,  0.0024647 ),\n",
       "       ('few',  0.00448679,  0.00307074),\n",
       "       ('batteri',  0.00445613,  0.00150124),\n",
       "       ('sound',  0.00445303,  0.00687892),\n",
       "       ('cabl',  0.00436015,  0.00274829),\n",
       "       ('cord',  0.00427724,  0.00239507),\n",
       "       ('mic',  0.00422665,  0.00345088),\n",
       "       ('stand',  0.00417273,  0.00269395),\n",
       "       ('cheap',  0.0039904 ,  0.00213509),\n",
       "       ('review',  0.00398323,  0.00051614)], \n",
       "      dtype=[('label', 'S10'), ('neg', '<f8'), ('pos', '<f8')])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(a, order='neg')[::-1][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words that clearly carry out a positive/negative feeling are observed. But they are mixed with other words that are only related to the products. It's because this analysis was performed on a dataset based on Instruments only. Thus, the positive/negative concept it biased by the terms related to the products people generally evaluate positively (or negatively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
